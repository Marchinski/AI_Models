{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN_pytorch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMRWhGR+xYtc6RnqYvKjeNj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":685},"id":"74obadlVgPo6","executionInfo":{"status":"error","timestamp":1617706619716,"user_tz":-120,"elapsed":106640,"user":{"displayName":"Marco Anselmi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0U0JOuMwYV4DqnkSV137siaZPIXCrJBo2bwDQ=s64","userId":"00713143189821467062"}},"outputId":"da0f9c10-d330-4428-c997-779c43a15ca7"},"source":["import os\n","import pickle\n","import time\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm import tqdm\n","\n","\n","class Generator(nn.Module):\n","    \"\"\"Image generator\n","    \n","    Takes a noise vector as input and syntheses a single channel image accordingly\n","    \"\"\"\n","\n","    def __init__(self, input_dims, output_dims):\n","        \"\"\"Init function\n","        \n","        Declare the network structure as indicated in CW2 Guidance\n","        \n","        Arguments:\n","            input_dims {int} -- Dimension of input noise vector\n","            output_dims {int} -- Dimension of the output vector (flatten image)\n","        \"\"\"\n","        super(Generator, self).__init__()\n","        ###  TODO: Change the architecture and value as CW2 Guidance required\n","        self.fc0 = nn.Sequential(nn.Linear(input_dims, 256), nn.LeakyReLU(0.2))\n","        # hidden layer 1\n","        self.fc1 = nn.Sequential(nn.Linear(256, 512), nn.LeakyReLU(0.2))\n","        # hidden layer 2\n","        self.fc2 = nn.Sequential(nn.Linear(512, 1024), nn.LeakyReLU(0.2))\n","        # output hidden layer\n","        self.fc3 = nn.Sequential(nn.Linear(1024, output_dims), nn.Tanh())\n","\n","    def forward(self, x):\n","        \"\"\"Forward function\n","        \n","        Arguments:\n","            x {Tensor} -- a batch of noise vectors in shape (<batch_size>x<input_dims>)\n","        \n","        Returns:\n","            Tensor -- a batch of flatten image in shape (<batch_size>x<output_dims>)\n","        \"\"\"\n","        ###  TODO: modify to be consistent with the network structure\n","        x = self.fc0(x)\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        x = self.fc3(x)\n","        return x\n","\n","\n","class Discriminator(nn.Module):\n","    \"\"\"Image discriminator\n","    \n","    Takes a image as input and predict if it is real from the dataset or fake synthesised by the generator\n","    \"\"\"\n","\n","    def __init__(self, input_dims, output_dims=1):\n","        \"\"\"Init function\n","        \n","        Declare the discriminator network structure as indicated in CW2 Guidance\n","        \n","        Arguments:\n","            input_dims {int} -- Dimension of the flatten input images\n","        \n","        Keyword Arguments:\n","            output_dims {int} -- Predicted probability (default: {1})\n","        \"\"\"\n","        super(Discriminator, self).__init__()\n","\n","        ###  TODO: Change the architecture and value as CW2 Guidance required\n","        self.fc0 = nn.Sequential(\n","            nn.Linear(input_dims, 1024),\n","            nn.LeakyReLU(0.2))\n","            #nn.Dropout(0.3)\n","        \n","        self.fc1 = nn.Sequential(\n","            nn.Linear(1024, 512),\n","            nn.LeakyReLU(0.2))\n","            #nn.Dropout(0.3)\n","        \n","        self.fc2 = nn.Sequential(\n","            nn.Linear(512, 256),\n","            nn.LeakyReLU(0.2))\n","            #nn.Dropout(0.3)\n","        \n","        self.fc3 = nn.Sequential(\n","            nn.Linear(256, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"Forward function\n","        \n","        Arguments:\n","            x {Tensor} -- a batch of 2D image in shape (<batch_size>xHxW)\n","        \n","        Returns:\n","            Tensor -- predicted probabilities (<batch_size>)\n","        \"\"\"\n","        ###  TODO: modify to be consistent with the network structure\n","\n","        x = self.fc0(x)\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        x = self.fc3(x)\n","        return x\n","\n","\n","def show_result(G_net, z_, num_epoch, show=False, save=False, path='result.png'):\n","    \"\"\"Result visualisation\n","    \n","    Show and save the generated figures in the grid fashion\n","    \n","    Arguments:\n","        G_net {[nn.Module]} -- The generator instant\n","        z_ {[Tensor]} -- Input noise vectors\n","        num_epoch {[int]} -- Indicate how many epoch has the generator been trained\n","    \n","    Keyword Arguments:\n","        show {bool} -- If to display the images (default: {False})\n","        save {bool} -- If to store the images (default: {False})\n","        path {str} -- path to store the images (default: {'result.png'})\n","    \"\"\"\n","\n","    ###  TODO: complete the rest of part\n","    # hint: use plt.subplots to construct grid\n","    # hint: use plt.imshow and plt.savefig to display and store the images\n","    f, a = plt.subplots(5, 5, figsize=(6, 6))\n","    p = 0\n","    for j in range(5):\n","        for i in range(5):\n","            a[j][i].imshow(np.reshape(G_net(z_).detach().cpu().numpy()[p], (28, 28)), cmap='gray')\n","            a[j][i].set_xticks(()); a[j][i].set_yticks(())\n","            p += 1\n","    f.suptitle('%i Epochs' % num_epoch)\n","    plt.savefig(path)\n","    plt.close()\n","\n","\n","def show_train_hist(hist, show=False, save=False, path='Train_hist.png'):\n","    \"\"\"Loss tracker\n","    \n","    Plot the losses of generator and discriminator independently to see the trend\n","    \n","    Arguments:\n","        hist {[dict]} -- Tracking variables\n","    \n","    Keyword Arguments:\n","        show {bool} -- If to display the figure (default: {False})\n","        save {bool} -- If to store the figure (default: {False})\n","        path {str} -- path to store the figure (default: {'Train_hist.png'})\n","    \"\"\"\n","    x = range(len(hist['D_losses']))\n","\n","    y1 = hist['D_losses']\n","    y2 = hist['G_losses']\n","\n","    plt.plot(x, y1, label='D_loss')\n","    plt.plot(x, y2, label='G_loss')\n","\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","\n","    plt.legend(loc=4)\n","    plt.grid(True)\n","    plt.tight_layout()\n","\n","    if save:\n","        plt.savefig(path)\n","\n","    if show:\n","        plt.show()\n","    else:\n","        plt.close()\n","\n","\n","def create_noise(num, dim):\n","    \"\"\"Noise constructor\n","    \n","    returns a tensor filled with random numbers from a standard normal distribution\n","    \n","    Arguments:\n","        num {int} -- Number of vectors\n","        dim {int} -- Dimension of vectors\n","    \n","    Returns:\n","        [Tensor] -- the generated noise vector batch\n","    \"\"\"\n","    return torch.randn(num, dim)\n","\n","\n","if __name__ == '__main__':\n","    # initialise the device for training, if gpu is available, device = 'cuda', else: device = 'cpu'\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    print(device)\n","    print(torch.__version__)\n","    data_dir = './MNIST_data/'\n","    save_dir = './MNIST_GAN_results/'\n","    image_save_dir = './MNIST_GAN_results/results'\n","\n","    # create folder if not exist\n","    if not os.path.exists(save_dir):\n","        os.mkdir(save_dir)\n","    if not os.path.exists(image_save_dir):\n","        os.mkdir(image_save_dir)\n","\n","    # training parameters\n","    batch_size = 100\n","    learning_rate = 0.0002\n","    epochs = 100\n","\n","    # parameters for Models\n","    image_size = 28\n","    G_input_dim = 100\n","    G_output_dim = image_size * image_size\n","    D_input_dim = image_size * image_size\n","    D_output_dim = 1\n","\n","    # construct the dataset and data loader\n","    transform = transforms.Compose([transforms.ToTensor(),\n","                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])\n","    train_data = datasets.MNIST(root=data_dir, train=True, transform=transform, download=True)\n","    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n","\n","    # declare the generator and discriminator networks    \n","    G_net = Generator(G_input_dim, G_output_dim).to(device)\n","    D_net = Discriminator(D_input_dim, D_output_dim).to(device)\n","\n","    # Binary Cross Entropy Loss function\n","    criterion = nn.BCELoss().to(device)\n","\n","    # Initialise the Optimizers\n","    G_optimizer = torch.optim.Adam(G_net.parameters(), lr=learning_rate)\n","    D_optimizer = torch.optim.Adam(D_net.parameters(), lr=learning_rate)\n","\n","    # tracking variables\n","    train_hist = {}\n","    train_hist['D_losses'] = []\n","    train_hist['G_losses'] = []\n","    train_hist['per_epoch_ptimes'] = []\n","    train_hist['total_ptime'] = []\n","\n","    start_time = time.time()\n","    # training loop\n","    for epoch in range(epochs):\n","        G_net.train()\n","        D_net.train()\n","        Loss_G = []\n","        Loss_D = []\n","        epoch_start_time = time.time()\n","        for (image, _) in tqdm(train_loader):\n","            image = image.to(device)\n","            b_size = len(image)\n","            # creat real and fake labels\n","            real_label = torch.ones(b_size, 1).to(device)\n","            fake_label = torch.zeros(b_size, 1).to(device)\n","\n","            # generate fake images \n","            data_fake = G_net(create_noise(b_size, G_input_dim).to(device))\n","            data_real = image.view(b_size, D_input_dim)\n","\n","            # --------train the discriminator network----------\n","            # compute the loss for real and fake images\n","            output_real = D_net(data_real)\n","            output_fake = D_net(data_fake)\n","            loss_real = criterion(output_real, real_label)\n","            loss_fake = criterion(output_fake, fake_label)\n","            loss_d = loss_real + loss_fake\n","\n","            # back propagation\n","            D_optimizer.zero_grad()\n","            loss_d.backward()\n","            D_optimizer.step()\n","\n","            # -------- train the generator network-----------\n","            data_fake = G_net(create_noise(b_size, G_input_dim).to(device))\n","\n","            # compute the loss for generator network\n","            output_fake = D_net(data_fake)\n","            loss_g = criterion(output_fake, real_label)\n","\n","            ## back propagation\n","            G_optimizer.zero_grad()\n","            loss_g.backward()\n","            G_optimizer.step()\n","\n","            ## store the loss of each iter\n","            Loss_D.append(loss_d.item())\n","            Loss_G.append(loss_g.item())\n","\n","        epoch_loss_g = np.mean(Loss_G)  # mean generator loss for the epoch\n","        epoch_loss_d = np.mean(Loss_D)  # mean discriminator loss for the epoch\n","        epoch_end_time = time.time()\n","        per_epoch_ptime = epoch_end_time - epoch_start_time\n","\n","        print(\"Epoch %d of %d with %.2f s\" % (epoch + 1, epochs, per_epoch_ptime))\n","        print(\"Generator loss: %.8f, Discriminator loss: %.8f\" % (epoch_loss_g, epoch_loss_d))\n","\n","        path = image_save_dir + '/MNIST_GAN_' + str(epoch + 1) + '.png'\n","        if (epoch + 1) == 10 or (epoch + 1) == 20 or (epoch + 1) == 50 or (epoch + 1) == 100:\n","            show_result(G_net, create_noise(25, 100).to(device), (epoch + 1), save=True, path=path)\n","\n","        # record the loss for every epoch\n","        train_hist['G_losses'].append(epoch_loss_g)\n","        train_hist['D_losses'].append(epoch_loss_d)\n","        train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n","\n","    end_time = time.time()\n","    total_ptime = end_time - start_time\n","    train_hist['total_ptime'].append(total_ptime)\n","\n","    print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (\n","        np.mean(train_hist['per_epoch_ptimes']), epochs, total_ptime))\n","    print(\"Training finish!... save training results\")\n","    with open(save_dir + '/train_hist.pkl', 'wb') as f:\n","        pickle.dump(train_hist, f)\n","    show_train_hist(train_hist, save=True, path=save_dir + '/MNIST_GAN_train_hist.png')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["  0%|          | 3/600 [00:00<00:21, 27.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["cuda\n","1.8.1+cu101\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 600/600 [00:21<00:00, 28.28it/s]\n","  0%|          | 3/600 [00:00<00:21, 27.77it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 of 100 with 21.22 s\n","Generator loss: 2.17692032, Discriminator loss: 1.13334508\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 600/600 [00:21<00:00, 28.46it/s]\n","  0%|          | 3/600 [00:00<00:21, 27.64it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2 of 100 with 21.09 s\n","Generator loss: 5.40185146, Discriminator loss: 1.52754968\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 600/600 [00:21<00:00, 28.39it/s]\n","  0%|          | 3/600 [00:00<00:20, 28.98it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 3 of 100 with 21.14 s\n","Generator loss: 6.58465646, Discriminator loss: 0.99478640\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 600/600 [00:20<00:00, 28.63it/s]\n","  0%|          | 3/600 [00:00<00:20, 29.59it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 4 of 100 with 20.96 s\n","Generator loss: 3.20058769, Discriminator loss: 1.07567874\n"],"name":"stdout"},{"output_type":"stream","text":[" 98%|█████████▊| 589/600 [00:20<00:00, 28.34it/s]"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-7ecde15e6412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mLoss_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mb_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \"\"\"\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}